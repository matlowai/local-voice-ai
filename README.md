<div align="center">
  <img src="./voice-assistant-frontend/.github/assets/app-icon.png" alt="App Icon" width="80" />
  <h1>ğŸ§  Local Voice Agent</h1>
  <p>A full-stack, Dockerized AI voice assistant with speech, text, and voice synthesis powered by <a href="https://livekit.io/">LiveKit</a>.</p>
  <img src="./voice-assistant-frontend/.github/assets/frontend-screenshot.jpeg" alt="Screenshot" width="600" />
</div>

---

## ğŸ§© Overview

This repo contains everything needed to run a real-time AI voice assistant locally using:

- ğŸ™ï¸ **LiveKit Agents** for STT â†” LLM â†” TTS
- ğŸ§  **Ollama** for running local LLMs
- ğŸ—£ï¸ **Kokoro** for TTS voice synthesis
- ğŸ‘‚ **Whisper (via VoxBox)** for speech-to-text
- ğŸ’¬ **Next.js + Tailwind** frontend UI
- ğŸ³ Fully containerized via Docker Compose

## ğŸ Quick Start

```bash
./test.sh
```

This script:
- Cleans up existing containers
- Builds all services
- Launches the full stack (agent, LLM, STT, TTS, frontend, and signaling server)

Once it's up, visit [http://localhost:3000](http://localhost:3000) in your browser to start chatting.

## ğŸ“¦ Architecture

```
[Frontend] â†’ [LiveKit Room] â† [Agent]
                        â†˜        â†™
              [Whisper]   [Ollama]   [Kokoro]
```

Each service is containerized and communicates over a shared Docker network:
- `livekit`: WebRTC signaling server
- `agent`: Custom Python agent with LiveKit SDK
- `whisper`: Speech-to-text using `vox-box` and Whisper model
- `ollama`: Local LLM provider (e.g., `gemma3:4b`)
- `kokoro`: TTS engine for speaking responses
- `frontend`: React-based client using LiveKit components

## ğŸ§  Agent Instructions

Your agent lives in [`agent/myagent.py`](./agent/myagent.py). It uses:
- `openai.STT` â†’ routes to Whisper
- `openai.LLM` â†’ routes to Ollama
- `groq.TTS` â†’ routes to Kokoro
- `silero.VAD` â†’ for voice activity detection

All metrics from each component are logged for debugging.

## ğŸ” Environment Variables

You can find environment examples in:
- [`/.env`](./.env)
- [`/agent/.env`](./agent/.env)
- [`/voice-assistant-frontend/.env.example`](./voice-assistant-frontend/.env.example)

These provide keys and internal URLs for each service. Most keys are placeholders for local dev use.

## ğŸ§ª Testing & Dev

To test or redeploy:

```bash
docker-compose down -v --remove-orphans
docker-compose up --build
```

The services will restart and build fresh containers.

## ğŸ§° Project Structure

```
.
â”œâ”€â”€ agent/                     # Python voice agent
â”œâ”€â”€ ollama/                    # LLM serving
â”œâ”€â”€ whisper/                   # Whisper via vox-box
â”œâ”€â”€ livekit/                   # Signaling server
â”œâ”€â”€ voice-assistant-frontend/ # Next.js UI client
â””â”€â”€ docker-compose.yml         # Brings it all together
```

## ğŸ“· Screenshots

![UI Screenshot](./voice-assistant-frontend/.github/assets/frontend-screenshot.jpeg)

## ğŸ› ï¸ Requirements

- Docker + Docker Compose
- No GPU required (uses CPU-based models)
- Recommended RAM: 18GB+

## ğŸ™Œ Credits

- Built with â¤ï¸ by [LiveKit](https://livekit.io/)
- Uses [LiveKit Agents](https://docs.livekit.io/agents/)
- Local LLMs via [Ollama](https://ollama.com/)
- TTS via [Kokoro](https://github.com/remsky/kokoro)
